2025 State of AI-assisted Software Development: Key Findings Briefing
The central focus for technology leaders in 2025 has shifted from if they should adopt AI to how to realize its value. DORA’s research confirms that AI’s primary role in software development is that of an amplifier. It magnifies the strengths of high-performing organizations and the dysfunctions of struggling ones.
The key takeaway is that the greatest returns on AI investment depend not on the tools themselves, but on a strategic focus on the underlying organizational system, including the clarity of workflows and the quality of the internal platform.
--------------------------------------------------------------------------------
I. AI Adoption and Use Landscape
AI adoption in software development has become virtually universal:
• Adoption Rate: Ninety percent (90%) of survey respondents report using AI at work, representing a 14.1% increase over the previous year.
• Perceived Productivity: More than 80% of respondents believe AI has increased their productivity. However, 41% of those only report a "slightly increased" impact.
• Code Quality Perception: A majority (59%) of respondents observe that AI has positively impacted their code quality.
• Trust and Skepticism: While adoption is widespread, 30% of those surveyed report little to no trust in the code generated by AI. This pattern reflects a healthy "trust but verify" approach, similar to how developers treat solutions found on Stack Overflow.
• Time and Reliance: The median time spent interacting with AI on a recent workday was two hours, which is about one-quarter of an eight-hour workday. Furthermore, 65% of AI users report relying on AI at work a "moderate amount," "a lot," or "a great deal".
• Primary Task: The number one use for AI tools among respondents whose jobs involve writing code is writing new code (71% use AI for this).
--------------------------------------------------------------------------------
II. AI’s Measured Impact on Key Outcomes
The 2025 research reveals significant shifts compared to the previous year, suggesting that people, teams, and tools have adapted:
A. Positive Relationships (Shifts and Steady Gains)
Outcome Category
2025 Finding
Context / Comparison to 2024
Software Delivery Throughput
Higher levels associated with AI adoption.
Reversed from negative last year, suggesting adaptation. If AI handles grunt work like scaffolding and boilerplate, developers may deploy code more frequently.
Product Performance
Higher levels associated with AI adoption.
Shifted from neutral last year, suggesting adaptation.
Valuable Work
Higher percentage of time doing valuable work associated with AI adoption.
Reversed from negative last year. This suggests people are learning to offload mundane tasks to AI and focus on problem-solving or creative work.
Individual Effectiveness
Higher levels associated with AI adoption.
Consistent positive association since 2024.
Organizational Performance
Higher levels associated with AI adoption.
Consistent positive association since 2024.
Code Quality
Higher levels associated with AI adoption.
Consistent positive association since 2024.
Team Performance
Higher levels associated with AI adoption.
Consistent positive association since 2024.
B. Stubborn Results (Systemic Challenges)
AI adoption has failed to improve key outcomes related to the organizational system, which DORA researchers suggest is because these outcomes reside beyond the individual’s purview:
• Software Delivery Instability: AI adoption still increases instability. This suggests that while teams are adapting for speed, their underlying systems have not yet evolved to safely manage AI-accelerated development.
• Burnout: AI adoption shows no relationship with burnout. Burnout is heavily influenced by work culture, leadership, and priority stability, factors that AI tools do not solve directly.
• Friction: AI adoption shows no relationship with friction. Friction often shifts from manual grind (e.g., writing code) to verifying AI output and prompt iteration, possibly netting out to no change in total friction.
--------------------------------------------------------------------------------
III. The DORA AI Capabilities Model: Amplifying AI’s Value
The DORA AI Capabilities Model identifies seven foundational practices—encompassing both technical and cultural aspects—that are proven to amplify the positive impact of AI on organizational performance:
Capability
Impact Amplified by High AI Adoption
Key Insight
Clear and Communicated AI Stance
Individual Effectiveness, Organizational Performance, Decreases Friction.
Clarity builds trust and provides the psychological safety needed for effective experimentation. The clarity of the policy is what matters, not the specific content.
User-centric Focus
Team Performance.
Critical requirement: In the absence of a user-centric focus, AI adoption can have a negative impact on team performance.
Quality Internal Platforms
Organizational Performance.
A high-quality internal platform (which 90% of organizations have adopted) is the essential foundation for AI success. It acts as a distribution and governance layer to scale AI benefits systemically.
Healthy Data Ecosystems
Organizational Performance.
Investment in high-quality, accessible, and unified data ecosystems yields higher organizational benefits than AI adoption alone.
AI-accessible Internal Data
Individual Effectiveness and Code Quality.
Connecting AI tools to internal systems moves beyond generic assistance, providing company-specific context necessary for maximal effectiveness.
Strong Version Control Practices
Individual Effectiveness (via frequent commits) and Team Performance (via frequent rollbacks).
The ability to quickly rollback changes is a critical safety net, enabling speed and resilience, especially important when the velocity of AI-generated code increases instability.
Working in Small Batches
Product Performance and Decreases Friction.
This practice ensures that individual productivity gains translate into measurable improvements rather than local acceleration being lost to downstream chaos.
--------------------------------------------------------------------------------
IV. Strategic Enablers: Platform Engineering and VSM
Platform Engineering (PE)
Platform engineering adoption is nearly universal (90%).
• Force Multiplier: A high-quality internal platform is a strategic prerequisite for unlocking the organizational value of AI, amplifying its effects on organizational performance.
• Risk Management: A great platform manages risk by making failure cheap and easily reversed. The platform acts as a safety net, applying automated testing and deployment processes regardless of whether code was created by hand or by AI.
• Holistic Experience: Developers perceive the platform as a single entity, and its overall effectiveness matters more than the quality of any individual feature.
Value Stream Management (VSM)
VSM, the practice of visualizing, analyzing, and improving the flow of work from idea to customer, acts as a force multiplier for AI investments.
• Organizational Advantage: Strong VSM practices ensure AI is applied to the right problems, channeling productivity gains toward solving system-level constraints rather than creating downstream chaos.
• Measurable Benefits: Organizations embracing VSM principles report markedly higher team performance, spend significantly more time on valuable work, and achieve better product outcomes.
--------------------------------------------------------------------------------
V. Software Delivery Performance: Seven Team Profiles
The research identified seven distinct team profiles by analyzing the interplay between performance, well-being, and environment:
• Harmonious High-achiever (Cluster 7): Represents 20% of respondents. This cluster shows excellence: positive metrics across well-being, product outcomes, and software delivery, operating in a stable, low-friction environment sustainably and without burnout.
• Pragmatic Performers (Cluster 6): Represents 20% of respondents. These teams deliver work with impressive speed and stability (better-than-average throughput, low instability). However, their team well-being (burnout/friction) is only at average levels.
• Excellence is Achievable: Clusters 6 and 7 combined represent nearly 40% of the total sample, providing empirical evidence that high-velocity, high-quality software delivery is an observable reality, confirming that the "speed vs. stability" trade-off is a myth.
• Legacy Bottleneck (Cluster 2): Represents 11% of respondents. These teams are in a constant state of reaction, dictated by unstable systems, leading to low product performance, ongoing quality issues, and high friction/burnout.
• Constrained by Process (Cluster 3): Represents 17% of respondents. These teams suffer from high burnout and low impact because effort is consumed by inefficient processes, despite operating on stable and reliable systems.
